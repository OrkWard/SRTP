{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022.6#2\n",
    "\n",
    "本周进行的学习分为两个部分：基于 softmax 回归的图像分类（单层），随后建立一个仅包括全连接层的多层网络来进行同样的任务。\n",
    "\n",
    "> 一点说明：在学习路线方面我们并非没有方向，但在之前的报告中没有明确表明。我们的计划是从最简单的结构开始，从单层、多层过渡到多块，在此过程中熟悉各类损失函数、优化方法和理解训练过程。这个过程持续到能独立建立一个卷积神经网络为止，大概在6月底前完成，然后我们开始项目导向的学习和实践。\n",
    ">\n",
    "> 为了尽快跟项目接轨，在进行网络搭建时我们会以图像分类任务为主。\n",
    ">\n",
    "> 此外，下周开始我们会接触一些文献中公开的遥感图像模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数学部分\n",
    "在图像分类任务中，输出结果常使用 one-hot 编码，即对于 n 个需要判断的类别输出一个n维向量，每个维度代表了模型判断为该类别的可能性。虽然此处的图像分类是针对整幅图像的，但也可以用于单个像元。\n",
    "\n",
    "针对该输出使用的损失函数是交叉熵损失。这是一种基于最大似然法的评价，将损失函数定义为负对数似然：\n",
    "$$\n",
    "-\\log P(\\mathbf{Y} \\mid \\mathbf{X})=\\sum_{i=1}^{n}-\\log P\\left(\\mathbf{y}^{(i)} \\mid \\mathbf{x}^{(i)}\\right)=\\sum_{i=1}^{n} l\\left(\\mathbf{y}^{(i)}, \\hat{\\mathbf{y}}^{(i)}\\right)\n",
    "$$\n",
    "能推导得到损失函数为\n",
    "$$\n",
    "l(\\mathbf{y}, \\hat{\\mathbf{y}})=-\\sum_{j=1}^{q} y_{j} \\log \\hat{y}_{j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码部分\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "# 加载数据。这里使用了经典的MNIST数据集。\n",
    "# batch大小为50，读入后转为Tensor\n",
    "batch_size = 50\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=trans, download=True)\n",
    "loader_train = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=8)\n",
    "loader_test = data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "# 一层用于展开数据，另一层为softmax运算\n",
    "# 该数据集每张图片大小为28x28，共10类，因此仿射矩阵为784x10\n",
    "# 单张图片存储为1x28x28，用Flatten展开为长为784的向量\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.Flatten(1, -1), nn.Linear(784, 10))\n",
    "\n",
    "# 初始化参数\n",
    "nn.init.normal_(net[1].weight, std=0.01)\n",
    "\n",
    "# 使用交叉熵损失\n",
    "# 这个函数并不如数学上定义的那么简单，隐藏了大量细节，使得我们只需要传入模型计算得到的概率矩阵即可\n",
    "# 在实际做softmax运算中需要考虑到指数函数的溢出可能，需要使用各种手段避免\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# 随机梯度下降，学习率0.1\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个周期，损失为0.608028，预测精度为0.8189\n",
      "第2个周期，损失为0.484256，预测精度为0.8276\n",
      "第3个周期，损失为0.462866，预测精度为0.831\n",
      "第4个周期，损失为0.449367，预测精度为0.806\n",
      "第5个周期，损失为0.439492，预测精度为0.8396\n",
      "第6个周期，损失为0.432865，预测精度为0.8418\n",
      "第7个周期，损失为0.427378，预测精度为0.8414\n",
      "第8个周期，损失为0.423323，预测精度为0.8391\n",
      "第9个周期，损失为0.420658，预测精度为0.8169\n",
      "第10个周期，损失为0.419874，预测精度为0.8385\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "# 训练过程与上一次一致。多余的代码是为了计算每个周期训练结束后的模型有效性，输出各种度量。\n",
    "\n",
    "# 10个周期\n",
    "epoch_nums = 10\n",
    "\n",
    "def accuracy(y_hat, y): \n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):  \n",
    "    \"\"\"计算当前模型的预测精度\"\"\"\n",
    "    correct, count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            correct += accuracy(net(X), y)\n",
    "            count += y.numel()\n",
    "    return correct / count\n",
    "\n",
    "for epoch in range(epoch_nums):\n",
    "    loss_acc, count = 0, 0 # 损失总和、数据集计数\n",
    "    for X, y in loader_train:\n",
    "        l = loss(net(X), y)\n",
    "        loss_acc += l.sum()\n",
    "        count += y.numel()\n",
    "        trainer.zero_grad()\n",
    "        l.mean().backward()\n",
    "        trainer.step()\n",
    "    print(f'第{epoch + 1}个周期，损失为{loss_acc / count:f}，预测精度为{evaluate_accuracy(net, loader_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着周期数增加预测精度在达到一定程度后反而下降，而且非常不稳定。经测试（50个周期），增加训练量也不会带来明显的改变，相对于图像的复杂来说，这种简单的模型显然不能很好地学习特征表达。\n",
    "\n",
    "现在我们搭建第一个有一定深度的网络。在原来一个输入层和一个输出层的基础上插入中间的全连接层，或被称为隐藏层。首先尝试插入一个隐藏层。激活函数使用最简单的ReLU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个周期，损失为0.645036，预测精度为0.8278\n",
      "第2个周期，损失为0.432445，预测精度为0.8249\n",
      "第3个周期，损失为0.386978，预测精度为0.8427\n",
      "第4个周期，损失为0.360641，预测精度为0.861\n",
      "第5个周期，损失为0.340659，预测精度为0.8719\n",
      "第6个周期，损失为0.325347，预测精度为0.8667\n",
      "第7个周期，损失为0.311953，预测精度为0.8722\n",
      "第8个周期，损失为0.301817，预测精度为0.8654\n",
      "第9个周期，损失为0.289214，预测精度为0.8676\n",
      "第10个周期，损失为0.281806，预测精度为0.8776\n"
     ]
    }
   ],
   "source": [
    "# 上面已经定义了数据迭代器，损失函数不作改变直接复用，因此需要做的只有重新定义网络\n",
    "\n",
    "h1 = 256    # 第一个隐藏层节点数\n",
    "\n",
    "net = nn.Sequential(nn.Flatten(),           # 输入层，图像展开为向量\n",
    "                    nn.Linear(784, h1),     # 隐藏层\n",
    "                    nn.ReLU(),              # 激活\n",
    "                    nn.Linear(h1, 10))      # 输出层\n",
    "\n",
    "# 需要初始化参数的层有多个\n",
    "def init_weights(layer):\n",
    "    if type(layer) == nn.Linear:\n",
    "        nn.init.normal_(layer.weight, std=0.01)\n",
    "net.apply(init_weights)\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# 训练过程也完全一致，写成函数\n",
    "def train(epoch_nums, loader_train, loader_test, net, loss, trainer):\n",
    "    for epoch in range(epoch_nums):\n",
    "        loss_acc, count = 0, 0\n",
    "        for X, y in loader_train:\n",
    "            l = loss(net(X), y)\n",
    "            loss_acc += l.sum()\n",
    "            count += y.numel()\n",
    "            trainer.zero_grad()\n",
    "            l.mean().backward()\n",
    "            trainer.step()\n",
    "        print(f'第{epoch + 1}个周期，损失为{loss_acc / count:f}，预测精度为{evaluate_accuracy(net, loader_test)}')\n",
    "train(10, loader_train, loader_test, net, loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个周期，损失为2.137360，预测精度为0.4716\n",
      "第2个周期，损失为0.858522，预测精度为0.7591\n",
      "第3个周期，损失为0.529881，预测精度为0.8246\n",
      "第4个周期，损失为0.434721，预测精度为0.8244\n",
      "第5个周期，损失为0.388862，预测精度为0.8428\n",
      "第6个周期，损失为0.359802，预测精度为0.8535\n",
      "第7个周期，损失为0.337452，预测精度为0.8666\n",
      "第8个周期，损失为0.323444，预测精度为0.8633\n",
      "第9个周期，损失为0.306651，预测精度为0.8695\n",
      "第10个周期，损失为0.295061，预测精度为0.8662\n"
     ]
    }
   ],
   "source": [
    "# 再加入另外两个隐藏层\n",
    "# 此处三个超参数为随意确定\n",
    "h1, h2, h3 = 256, 128, 64\n",
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(784, h1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(h1, h2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(h2, h3),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(h3, 10))\n",
    "net.apply(init_weights)\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "train(10, loader_train, loader_test, net, loss, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential添加网络层的方式非常自然而舒适。现在整个网络运行模式已经比较清晰，但我们还没有引入*块*（从代码的视角来看是*类*）。\n",
    "\n",
    "我们下周计划接触一些公开的遥感图像分类训练模型，并尝试用在我们的数据上。同时我们也借此机会彻底整理数据并上传。\n",
    "\n",
    "**有一些实践上的问题。我们注意到四层的全连接层并不比两层的表现有明显提高。但首先要考虑到这个模型的简单性，稳定在85%以上的精度并不算一个很差的表现，因此增加层数也很难更进一步，可能需要超参数上微妙的调整。**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e9c955df6178b2e3d07b55dfed71eee1bcf21dc3da9caa7365344dfc4fda2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hyperspectral')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
