# 2022.7#5

我们找到一篇文献《Deep Learning for Classification
of Hyperspectral Data: A Comparative Review》，从高光谱影像分类任务的描述、数据的介绍、经典方法到深度学习方法都有所介绍，同时也提供了一个包含许多开箱即用实现的分类工具包和实验过程，我们认为这是一个很好的学习范本。在仔细的通读了全文之后，我们选择性地阅读了一些文中介绍的各种方法所对应的文献。

《Investigation of the random forest framework for classification of hyperspectral data》介绍了将基于二分类的随机森林用于高光谱图像时的表现。由于决策树的二份类性，比较相似的类会先被分在同一个大类中，随后在进一步的细分过程中再被分类。作者指出这一机制很可能有效提高了分类的准确性。

《Classification of Hyperspectral Remote Sensing Images With Support Vector Machines》介绍了 SVM 在 HSI 分类中的应用。但大概读下来，在将单类扩展到多类的步骤上和决策树大同小异，关键在于先进行特征空间重投影，再用超平面进行多次划分。SVM 本身的优越之处在于不容易受到高维数据的影像，而且计算效率高，在多分类过程中能跳过重复性的计算。

传统的浅学习算法最大难点在于提高 featrue representation 的效率，使其尽可能地将特征空间中不同类别的点区分开来。深度学习的优势则在于同时训练特征表现和分类算法，使它们互相之间能最好地配合。

早期的深度学习方法，特别是基于卷积的方法基本上会先将 HSI 投影为三波段 RGB 影像，这是由于难以处理过大的数据量的限制。很快就注意到这种方式不可避免地抛弃了原图中的许多特征，因此有了另外的一些特别的投影方式，《Spectral-Spatial Feature Extraction for Hyperspec-
tral Image Classification: A Dimension Reduction and Deep Learning Approach》中就提出了一种将 3D 数据直接展开为 2D 或 1D 的方式。后出现的一些方法并没有改变降维的思想，而是将降维的过程也纳入训练的范围。

《Going deeper with contextual cnn for hyper-spectral image classification》采用了一种 2D+1D 的混合 CNN，最值得注意的地方是预测点不仅只覆盖了卷积核中心点，而是覆盖了所有输入像素。随后的一些 3D CNN 方法也只是在 2D+1D 的基础上进行了改进。

本周我们花了很多时间看文献，但除了一些介绍、总结性质的描述外，没有仔细地深入细节。在看文献的过程中，经常遇到作者在前人的基础上进行了拓展工作，而又要画时间去看过去的文献的情况，想要透彻理解一种方法并不容易。接下来我们会选取其中一篇文献尝试复现，感受一下实际应用中从建模到测试的全过程。