本周我们首先整理了收集到的数据，并对其进行了格式转换。
## 数据介绍
### [Houston Hyperspectral Data Set](https://hyperspectral.ee.uh.edu/?page_id=459)
由 [Data Fusion Technical Committee](http://www.grss-ieee.org/community/technical-committees/data-fusion/) of the IEEE Geoscience and Remote Sensing Society (GRSS) 在2013年举办的 Data Fusion Contest 中提供的比赛用数据集，分辨率为 2.5m，包括从 380nm 到 1050nm 的 144 个波段，在 Houston 校园及其附近获取。
### [Indian Pine Data Set](https://purr.purdue.edu/publications/1947/1)
由 [AVIRIS](http://aviris.jpl.nasa.gov/) 在 Indian Creek 和 Pine Creek 分水岭附近拍摄的数据集，该数据最初由 Prof. Marion Baumgardner 和他的学生申请用于土壤研究，包含 400nm 到 2500nm 的 220 个波段。
AVIRIS 是来自 NASA 的一组用于获取高光谱影像用于进行遥感研究的设备。下面几个数据集同样来自 AVIRIS。
### Salinas Scene
[AVIRIS sensor](http://aviris.jpl.nasa.gov/) 在 California 的 Salinas Valley 拍摄的数据集，分辨率为 3.7m，包括 224 个波段。Salinas-A 是 Salinas 的一个子集。
### Kennedy Space Center
AVIRIS 在 Kennedy Space Center 拍摄的数据集，在 20km 的高空拍摄，分辨率较低，仅 18m，224 个波段。
### Cuprite
来自 AVIRIS。
### Jasper Ridge
来自 AVIRIS。
### Pavia Centre and University Data Set
两个由 [ROSIS sensor](http://www.opairs.aero/rosis_en.html) 分别在 Pavia Centre 和 Pavia University 拍摄的数据集，分别包括 103 个和 102 个波段，分辨率高达 1.3m。
### Botswana
由 NASA EO-1 卫星在 Botswana 的 Okavango Delta 拍摄的数据集，覆盖了超过 7.7km，分辨率仅 30m，原始数据有 242 个波段。
### Samson Data Set
发布页面已不可访问。覆盖从 401nm 到 889nm 的 156 个波段，原始图像大小为 952x952 像素，通常使用的是三个子集，分别称为 Samson#1，Samson#2，Samson#3。
###  Urban
由 HYDICE sensor 提供的数据集。有三种不同版本的ground truth，分别包括了不同数量的 endmember。
### **The China and **USA** Dataset**
由 Hyperion sensor 提供的在江苏盐城和 Hermiston city in Umatilla County 拍摄的数据集。
### The Washington DC Mall
由 Spectral Information Technology Application Center of Virginia 提供的数据集。
## 预处理和格式转换
### TIFF revision 6.0 [baseline]
虽然处理数据主要是使用工具，但我们借这个机会研究了一下 Tiff 文件的标准规范，参考文档是 Adobe 在 1992 年发布的 6.0 修订版，只查阅了非 extension 的部分。
基本组成形式是 8 字节的 IFH（image file header）——图像数据——IFD（image file directory），图像数据和 IFD 顺序可以交换；
IFH 第一个字指明小端/大端存储，第二个字固定 0x2A，第三个双字表示 IFD 的偏移；
一个 IFD 存储[一组]图像属性（DE，directory entry），文件中可能包含多个 IFD。第一个字表示属性个数，其次为若干个 12 字节的单个属性，最后是一个双字表示下一个 IFD 的位置或 NULL。
一个 DE 存储一个图像属性，包括一个字的标签，一个字的属性格式，4 字节的属性值的数量（可以有多个），4字节的属性值偏移，标签举例：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/22108982/1651397525854-7433a6d4-f23d-420b-ad1c-61926b94b161.png#clientId=u4b42990d-7d3f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=316&id=u329dd584&margin=%5Bobject%20Object%5D&name=image.png&originHeight=392&originWidth=770&originalType=binary&ratio=1&rotation=0&showTitle=false&size=85470&status=done&style=none&taskId=u5e7560ef-8c1a-4ca8-87d8-b0b8e2e7ee0&title=&width=621.1764506756293)
在生成新的 tif 文件时需要自行添加信息，如部分 .mat 格式的数据只是一个单纯的三维空间矩阵，色彩空间（Photometric）信息只能通过手动添加，通过查看其他数据的二进制码能快速获取需要填充的信息。
### 格式转换
目前我们已经完成了几乎全部数据的转换，部分结果如图：![image.png](https://cdn.nlark.com/yuque/0/2022/png/22108982/1651410381023-37a554ad-96bb-4336-bcbc-e10812e9ddec.png#clientId=ud51e486d-deff-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=871&id=u93e7b451&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1080&originWidth=1919&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1055391&status=done&style=none&taskId=u968a4f74-00b5-4a5b-ae49-5c09fa6cb8d&title=&width=1548.1007907097828)
有些数据是以 matlab 变量的格式存储的，因此我们也借这个机会接触了一点 matlab 图像处理的相关内容，包括基本的脚本语句结构、文件读写和数据类型。
我们还没有开始对空缺部分进行人工标注，部分数据标注量确实有些不足，如下面这份：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/22108982/1651410698113-57d0d6da-ad58-41d7-a06b-1810d92e95a9.png#clientId=ud51e486d-deff-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=649&id=ufd0eab3d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=804&originWidth=1438&originalType=binary&ratio=1&rotation=0&showTitle=false&size=550421&status=done&style=none&taskId=ub365bdd1-bb67-456d-af55-8fdd4a59da7&title=&width=1160.0671897033183)
同时我们学习了一些人工智能领域的基础概念，简单谈谈有哪些内容：
## 神经网络与深度学习
人工智能、机器学习和深度学习这些概念间的层级关系

1.  人工智能、机器学习与深度学习的关系：
（1）人工智能： 努力将通常由人类完成的智力任务自动化。
（2）机器学习： 在预先定义好的可能性空间中，利用反馈信号指引来寻找输入数据的有用表示。
（3）深度学习： 是从数据中学习表示的一种新方法，强调从连续的层中进行学习，这些层对应于越来越有意义的表示。
深度学习是机器学习的一个子集，而机器学习又是人工智能的一个子集。 
1.  深度学习可以被定义为四个基本网络框架中具有大量参数和层数的神经网络，分别为无监督预训练网络、卷积神经网络、循环神经网络和递归神经网络。其中：
（1） 卷积神经网络是用共享权重在空间中进行扩展的标准神经网络，主要是通过内部卷积来识别图片，内部卷积可以看到图像上识别对象的边缘；
（2） 循环神经网络是在时间上进行扩展的标准神经网络，它提取进入下一时间步的边沿，而不是在同一时间进入下一层；
（3） 递归神经网络更类似于分层网络，其中输入序列没有真正的时间面，但是必须以树状方式分层处理。 
1.  深度学习常用的算法有很多，在这里列出最为主要的两种算法的概念：
（1） 反向传播算法
简称BP算法。BP神经网络是由一个输入层、一个输出层和一个或多个隐层构成的，它的激活函数采用sigmoid函数。在这其中，输入信号经输入层输入，通过隐层计算由输出层输出，输出值与标记值比较，若有误差，将误差反向由输出层向输入层传播，在这个过程中，利用梯度下降算法对神经元权值进行调整。
（2） 随机梯度下降法
也称为增量梯度下降法，简称SGD算法。其是一种迭代方法，用于优化可微分目标函数。该方法通过在小批量数据上计算损失函数的梯度而迭代地更新权重与偏置项。 
## 遇到的问题

- 如果由我们自己进行标注如何保证数据的准确性？我们都没有受过专门的图像解译训练；
- 组员们对机器学习的理解还只停留在概念上，还未进行实践操作，在实践方面的经验仍有待补足。

